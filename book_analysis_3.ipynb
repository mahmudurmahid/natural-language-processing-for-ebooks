{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642d4111-85c1-4f41-a7dc-d13060ce03be",
   "metadata": {},
   "source": [
    "# Load the Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9236d1d5-1eef-47c2-a2c3-dacd0bd50739",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"miracle_in_the_andes.txt\", \"r\") as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7239ab1-7421-4317-8c7c-d5b98d41dbc4",
   "metadata": {},
   "source": [
    "# Find the most used words in the book (non-articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ca241f-150b-4ba6-a0d2-0e39099b8076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter', 'before', 'it', 'was', 'friday']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(\"[a-zA-Z]+\")\n",
    "findings = re.findall(pattern, book.lower())\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91441257-9bd9-4e23-bcae-045dc5b45e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "for word in findings:\n",
    "    if word in dictionary.keys():\n",
    "        dictionary[word] = dictionary[word] + 1\n",
    "    else:\n",
    "        dictionary[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d785470b-2457-4963-a729-ba2814974b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5346, 'the'),\n",
       " (2795, 'and'),\n",
       " (2729, 'i'),\n",
       " (2400, 'to'),\n",
       " (2060, 'of'),\n",
       " (1566, 'a'),\n",
       " (1430, 'was'),\n",
       " (1419, 'in'),\n",
       " (1226, 'we'),\n",
       " (1169, 'my')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_list = [(value, key) for (key, value) in dictionary.items()]\n",
    "d_list = sorted(dictionary_list, reverse=True)\n",
    "d_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa455f4f-1924-47b3-914c-e8f872406eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from nltk) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3.13 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2c6e5bb-25cb-47ae-a501-59794a598ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mahmudurmahid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91eef8de-8d2a-41a9-9fbc-cb7e9ebfacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = []\n",
    "\n",
    "for count, word in d_list:\n",
    "    if word not in english_stopwords:\n",
    "        filtered_words.append((word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab1862b2-106f-4f02-9dbe-6b79ac0768f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('would', 575),\n",
       " ('us', 519),\n",
       " ('said', 292),\n",
       " ('roberto', 284),\n",
       " ('could', 252),\n",
       " ('one', 249),\n",
       " ('snow', 227),\n",
       " ('mountain', 183),\n",
       " ('time', 182),\n",
       " ('like', 165)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df67d86-c5ed-4537-99d9-e5a96a39f9fc",
   "metadata": {},
   "source": [
    "# Sentiment analysis: what is the most positive and negative chapter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60142bf-ebb2-4933-ba4a-beb3159ee1a2",
   "metadata": {},
   "source": [
    "###Â Example of SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77d11e49-d6a3-4d5e-8a3b-2a1fc21bc823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/mahmudurmahid/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b21c83e3-7904-43af-ac61-7f5f2c3a4c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dabc6514-e606-46db-90ce-ab58fa1d383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = analyzer.polarity_scores(\"That yacht is huge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d78b79c-724e-4e09-ae27-5df54d13874f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a positive text\n"
     ]
    }
   ],
   "source": [
    "if scores[\"pos\"] > scores[\"neg\"]:\n",
    "    print(\"This is a positive text\")\n",
    "else:\n",
    "    print(\"This is a negative text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "806f6729-0989-4528-9b99-c6e062277e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.116, 'neu': 0.76, 'pos': 0.125, 'compound': 1.0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a9471-9ecd-44bc-81f0-660f3845cd76",
   "metadata": {},
   "source": [
    "### Chapter sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2800ef67-3c2d-4e04-9f8a-69c16b238d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(\"Chapter [0-9]+\")\n",
    "chapters = re.split(pattern, book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe07beea-534c-4996-9d11-913933410982",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = chapters[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b1f5bba1-acc2-4b53-ad28-7ca7b78d6039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.141, 'neu': 0.721, 'pos': 0.138, 'compound': -0.9963}\n",
      "{'neg': 0.118, 'neu': 0.742, 'pos': 0.141, 'compound': 0.9997}\n",
      "{'neg': 0.124, 'neu': 0.761, 'pos': 0.115, 'compound': -0.9979}\n",
      "{'neg': 0.136, 'neu': 0.761, 'pos': 0.103, 'compound': -0.9999}\n",
      "{'neg': 0.12, 'neu': 0.786, 'pos': 0.094, 'compound': -0.9998}\n",
      "{'neg': 0.097, 'neu': 0.824, 'pos': 0.079, 'compound': -0.9996}\n",
      "{'neg': 0.086, 'neu': 0.733, 'pos': 0.181, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for chapter in chapters:\n",
    "    scores = analyzer.polarity_scores(chapter)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eaa6f815-8858-4727-9239-22bfc4374538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'neg': 0.141, 'neu': 0.721, 'pos': 0.138, 'compound': -0.9963}\n",
      "1 {'neg': 0.118, 'neu': 0.742, 'pos': 0.141, 'compound': 0.9997}\n",
      "2 {'neg': 0.124, 'neu': 0.761, 'pos': 0.115, 'compound': -0.9979}\n",
      "3 {'neg': 0.136, 'neu': 0.761, 'pos': 0.103, 'compound': -0.9999}\n",
      "4 {'neg': 0.12, 'neu': 0.786, 'pos': 0.094, 'compound': -0.9998}\n",
      "5 {'neg': 0.097, 'neu': 0.824, 'pos': 0.079, 'compound': -0.9996}\n",
      "6 {'neg': 0.086, 'neu': 0.733, 'pos': 0.181, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for number, chapter in enumerate(chapters):\n",
    "    scores = analyzer.polarity_scores(chapter)\n",
    "    print(number, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4339c213-6fbe-4a78-ab19-3a753b61ec86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
